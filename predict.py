# -*- coding: utf-8 -*-
"""
Created on Sun Apr 12 19:52:47 2020

@author: Sathish
interpolation for missing data
"""

from influxdb import InfluxDBClient,DataFrameClient
from configparser import ConfigParser, ExtendedInterpolation
from pytz import utc
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.jobstores.memory import MemoryJobStore
from apscheduler.executors.pool import ThreadPoolExecutor

import pandas as pd
from fbprophet import Prophet
import csv
from datetime import datetime
import logging
import logger_config



config = ConfigParser(interpolation=ExtendedInterpolation())
config.read('./config/application.ini')
default_config = config['common']

logger = logging.getLogger(__name__)


influxdb_config = config['influxdb']

from_pre_db = InfluxDBClient(host=influxdb_config['preprocessed_data_host'],
                                    port=influxdb_config['preprocessed_data_port'],
                                    database=influxdb_config['preprocessed_database'])

from_db_df = DataFrameClient(host=influxdb_config['preprocessed_data_host'],
                                    port=influxdb_config['preprocessed_data_port'],
                                    database=influxdb_config['preprocessed_database'])

from_forecast_db_df = DataFrameClient(host=influxdb_config['forecast_db_host'],
                                    port=influxdb_config['forecast_db_port'],
                                    database=influxdb_config['forecast_db'])


to_db = InfluxDBClient(host=influxdb_config['forecast_db_host'],
                                    port=influxdb_config['forecast_db_port'],
                                    database=influxdb_config['forecast_db'])


def predict(metric_name,from_db=from_forecast_db_df, to_db=to_db):
    query = config['forecast']['query'].format(metric_name)
    res = from_db.query(query)
    for measurement in res:
        ret = res[measurement]
        df = pd.DataFrame.from_dict(ret)
        df['ds'] =df.index.astype(str).str[:-6]
        df['y'] = df['value']
    
        m = Prophet(interval_width=0.95)
        m.fit(df)
        future = m.make_future_dataframe(periods=50, freq='S')
        forecasts = m.predict(future)
        forecasts['ds'] = forecasts['ds'].astype(str)
        fileName = "./forecast/" + metric_name + "_forecasts" +  datetime.now().strftime("_%Y-%m-%d-%H-%M-%S") + ".csv"
        with open(fileName, 'w', newline='') as inputFile:
            writer = csv.writer(inputFile)
            writer.writerow(["measurement", "value", "value_lower", "value_higher"])
            for i in forecasts.itertuples(): 
                query = config['forecast']['query_exists']
                bp = {"input_time": i[1]}
                existing_data = from_pre_db.query(query,bind_params=bp)
                new_data = []
                if(not bool(existing_data)):
                    #data generated by forecasting
                    new_data = [
                        {
                            "measurement": measurement,
                            "fields": {
                                #yhat
                                "value": i[13],
                                #yhat_lower
                                "value_lower" : i[3],
                                #yhat_higher
                                "value_higher" : i[4]
                            },
                        "time": i[1]
                        }
                    ]        
                    print(new_data)
                    writer.writerow([measurement, i[13], i[3], i[4]])
                    to_db.write_points(new_data)

    
if __name__ == '__main__':
    jobstores = {
        'default': MemoryJobStore()
    }
    executors = {
        'default': ThreadPoolExecutor(20)
    }
    job_defaults = {
        'coalesce': False,
        'max_instances': 1
    }
    scheduler = BlockingScheduler(jobstores=jobstores, executors=executors, job_defaults=job_defaults, timezone=utc)
    #predict('Ax')
           
    metrics = config['forecast']['metrics'].split(',')
    for metric in metrics:
        kwArgs = {"metric_name": metric}
        logger.info("Adding job to prediction %s", metric)
        scheduler.add_job(predict, 'interval', name=metric, kwargs=kwArgs,seconds=int(default_config['query_mean_interval']))

    try:
        scheduler.start()
    finally:
        scheduler.shutdown()


